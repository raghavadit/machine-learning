{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "linear regression-prajakta",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raghavadit/machine-learning/blob/master/linear_regression_prajakta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJM8ymxD96uR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " class MyLinearRegression:\n",
        "    def __init__(self, weight=30 , bias=2, learning_rate=0.1,\n",
        "                 iterations=10):\n",
        "        self.weight = weight\n",
        "        self.bias = bias\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "        self.cost_trend = []\n",
        "        self.cost = 0\n",
        "\n",
        "    def predict(self, x):\n",
        "        predicted_set = []\n",
        "        for i in range(len(x)):\n",
        "            predicted_value = self.weight * x[i] + self.bias\n",
        "            predicted_set.append(predicted_value)\n",
        "        return predicted_set\n",
        "\n",
        "    def cost_function(self, x, y):\n",
        "        count = len(x)\n",
        "        total_error = 0.0\n",
        "        for i in range(count):\n",
        "            total_error += (y[i] - (self.weight * x[i] +\n",
        "                            self.bias)) ** 2\n",
        "        return float(total_error) / (2 * count)\n",
        "\n",
        "    def update_weights(self, x, y):\n",
        "        weight_deriv = 0\n",
        "        bias_deriv = 0\n",
        "        count = len(x)\n",
        "\n",
        "        for i in range(count):\n",
        "            # Calculate partial derivatives\n",
        "            # -2x(y - (mx + b))\n",
        "            weight_deriv += -2 * x[i] * (y[i] -(self.weight * x[i] + self.bias))\n",
        "\n",
        "            # -2(y - (mx + b))\n",
        "            bias_deriv += -2 * (y[i] - (self.weight * x[i] +\n",
        "                                self.bias))\n",
        "\n",
        "        # We subtract because the derivatives point in direction of steepest\n",
        "        # ascent\n",
        "        self.weight -= (weight_deriv / count) * self.learning_rate\n",
        "        self.bias -= (bias_deriv / count) * self.learning_rate\n",
        "\n",
        "    def train(self, x, y):\n",
        "        for i in range(self.iterations):\n",
        "            self.update_weights(x, y)\n",
        "            # Calculating cost\n",
        "            self.cost = self.cost_function(x, y)\n",
        "            self.cost_trend.append(self.cost)\n",
        "           # if i % 10000 == 0:\n",
        "            print(\"Iteration: {}\\t Weight: {}\\t Bias: {}\\t Cost: {}\".format(i, self.weight, self.bias, self.cost))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGMUmPfj96ua",
        "colab_type": "code",
        "outputId": "9cf6099b-8bc0-4f08-89db-adcf3120b8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# intialise data of lists. \n",
        "data = {'Hours':[2.5,5.1,3.2,8.5,3.5,1.5,9.2,5.5,8.3,2.7,7.7,5.9,4.5,3.3,1.1,8.9,2.5,1.9,6.1,7.4,2.7,4.8,3.8,6.9,7.8], \n",
        "        'Scores':[21,47,27,75,30,20,88,60,81,25,85,62,41,42,17,95,30,24,67,69,30,54,35,76,86]} \n",
        "  \n",
        "# Create DataFrame \n",
        "studentscores = pd.DataFrame(data) \n",
        "  \n",
        "# Print the output. \n",
        "studentscores "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hours</th>\n",
              "      <th>Scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.5</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.2</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.5</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.5</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.5</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9.2</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.5</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8.3</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.7</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.7</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5.9</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.5</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.3</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8.9</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2.5</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.9</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.1</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.4</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.7</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4.8</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3.8</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.9</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>7.8</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Hours  Scores\n",
              "0     2.5      21\n",
              "1     5.1      47\n",
              "2     3.2      27\n",
              "3     8.5      75\n",
              "4     3.5      30\n",
              "5     1.5      20\n",
              "6     9.2      88\n",
              "7     5.5      60\n",
              "8     8.3      81\n",
              "9     2.7      25\n",
              "10    7.7      85\n",
              "11    5.9      62\n",
              "12    4.5      41\n",
              "13    3.3      42\n",
              "14    1.1      17\n",
              "15    8.9      95\n",
              "16    2.5      30\n",
              "17    1.9      24\n",
              "18    6.1      67\n",
              "19    7.4      69\n",
              "20    2.7      30\n",
              "21    4.8      54\n",
              "22    3.8      35\n",
              "23    6.9      76\n",
              "24    7.8      86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyOqYPRdBpo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avh401TI11sH",
        "colab_type": "code",
        "outputId": "a325449d-1072-4be6-93fe-f7650b77e345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "x=[2.5,5.1,3.2,8.5,3.5,1.5,9.2,5.5,8.3,2.7,7.7,5.9,4.5,3.3,1.1,8.9,2.5,1.9,6.1,7.4,2.7,4.8,3.8,6.9,7.8] \n",
        "y=[21,47,27,75,30,20,88,60,81,25,85,62,41,42,17,95,30,24,67,69,30,54,35,76,86]\n",
        "plt.scatter(x,y,s=30)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LSp2jKt96uj",
        "colab_type": "code",
        "outputId": "8398866d-31b3-4ed9-e2a0-85d71466a323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "#from my_linear_regression import MyLinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing the dataset\n",
        "\n",
        "X = studentscores.iloc[:, :-1].values\n",
        "y = studentscores.iloc[:, -1].values\n",
        "X,y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[2.5],\n",
              "        [5.1],\n",
              "        [3.2],\n",
              "        [8.5],\n",
              "        [3.5],\n",
              "        [1.5],\n",
              "        [9.2],\n",
              "        [5.5],\n",
              "        [8.3],\n",
              "        [2.7],\n",
              "        [7.7],\n",
              "        [5.9],\n",
              "        [4.5],\n",
              "        [3.3],\n",
              "        [1.1],\n",
              "        [8.9],\n",
              "        [2.5],\n",
              "        [1.9],\n",
              "        [6.1],\n",
              "        [7.4],\n",
              "        [2.7],\n",
              "        [4.8],\n",
              "        [3.8],\n",
              "        [6.9],\n",
              "        [7.8]]),\n",
              " array([21, 47, 27, 75, 30, 20, 88, 60, 81, 25, 85, 62, 41, 42, 17, 95, 30,\n",
              "        24, 67, 69, 30, 54, 35, 76, 86]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvfKE_WT96un",
        "colab_type": "code",
        "outputId": "82d5890b-5cf0-47be-974f-ed0d1db98a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n",
        "\n",
        "# Fitting Simple Linear Regression to the Training set\n",
        "regressor = MyLinearRegression()\n",
        "regressor.train(X_train, y_train)\n",
        "print('Weight: ' + str(regressor.weight) + ' Bias: ' + str(regressor.bias))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = regressor.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ca2fc0898d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Fitting Simple Linear Regression to the Training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw0Vfxf996uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}